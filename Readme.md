# ğŸ“š RAG-Based AI Teaching Assistant

An end-to-end **Retrieval-Augmented Generation (RAG)** pipeline that converts video lectures into an intelligent AI assistant capable of answering context-aware questions.

This system transforms raw video content into structured knowledge using transcription, chunking, embeddings, and semantic retrieval â€” enabling grounded AI responses.

---

## ğŸš€ Project Overview

This project allows users to:

- Upload lecture videos (.mp4)
- Extract audio using FFmpeg
- Transcribe speech into text using Whisper
- Split transcripts into structured chunks
- Generate vector embeddings
- Store embeddings in a vector database
- Retrieve relevant content based on user queries
- Generate context-aware answers using an LLM

---

## ğŸ§  What is RAG?

**Retrieval-Augmented Generation (RAG)** is an AI architecture that:

1. Retrieves relevant information from a knowledge base
2. Augments the user query with retrieved context
3. Generates accurate responses using a language model

This ensures answers are grounded in actual lecture content rather than relying only on the modelâ€™s pre-trained knowledge.

---

## ğŸ—ï¸ System Architecture

Video Files (.mp4)
â†“
Audio Extraction (FFmpeg)
â†“
Speech-to-Text (Whisper)
â†“
Text Cleaning & Chunking
â†“
Embedding Generation
â†“
Vector Database Storage
â†“
User Query
â†“
Similarity Search (Top-K Retrieval)
â†“
LLM Response Generation

---

## âš™ï¸ Tech Stack

- Python
- OpenAI Whisper (Speech-to-Text)
- FFmpeg (Audio Extraction)
- Embedding Model
- Vector Database (FAISS / ChromaDB)
- LLM API (Response Generation)

---

## ğŸ“‚ Project Structure

RAG-Based-AI-Teaching-Assistant/
â”‚
â”œâ”€â”€ videos/ # Input lecture videos
â”œâ”€â”€ audio/ # Extracted MP3 files
â”œâ”€â”€ transcripts/ # Generated text transcripts
â”œâ”€â”€ embeddings/ # Stored vector embeddings
â”œâ”€â”€ rag_pipeline.py # Main pipeline script
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ”„ Workflow

### 1ï¸âƒ£ Video to Audio

Extract audio from lecture videos using FFmpeg.

### 2ï¸âƒ£ Audio to Text

Transcribe audio files into text using Whisper.

### 3ï¸âƒ£ Text Chunking

Split transcripts into smaller context-aware chunks.

### 4ï¸âƒ£ Embedding Creation

Convert text chunks into vector embeddings.

### 5ï¸âƒ£ Vector Storage

Store embeddings inside a vector database for semantic search.

### 6ï¸âƒ£ Query Processing

- Convert user query into embedding
- Retrieve top-k similar chunks
- Pass retrieved chunks + query to LLM
- Generate grounded response

---

## ğŸ¯ Key Features

âœ” End-to-end automated pipeline  
âœ” Handles large lecture datasets  
âœ” Semantic similarity-based retrieval  
âœ” Context-aware AI-generated responses  
âœ” Modular and reusable architecture

---

## ğŸ’¡ Example Use Case

User Question:
"What is the difference between supervised and unsupervised learning?"

System Process:

- Retrieves relevant lecture chunks
- Augments query with retrieved context
- Generates an accurate, course-grounded answer

---

## ğŸ§ª How to Run

```bash
# Install dependencies
pip install -r requirements.txt

# Run the pipeline
python rag_pipeline.py
```

---

## ğŸ“ˆ Future Improvements

- Add Streamlit or React frontend
- Add multi-language transcription support
- Implement hybrid search (keyword + semantic)
- Deploy on cloud (AWS/GCP/Azure)
- Add conversational memory

---

## ğŸ‘¨â€ğŸ’» Author
Mentor - @CodeWithHarry - Harish ALi Khan
Fahad Khan (Rixz)  
Aspiring Data Scientist | AI Engineer | Data Analsyt
Building practical AI systems with real-world applications.
